{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanjitp/CS4225/blob/main/cs4225_a2_colab_KanJitpakdi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Spark SQL (15m)"
      ],
      "metadata": {
        "id": "c9TcaCrlWvhN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MkbrHZYEw5Cr"
      },
      "outputs": [],
      "source": [
        "# Setup Spark\n",
        "# ===============\n",
        "# Installing Spark needs to be done once each time you re-open this notebook. It should take around 10-30 seconds.\n",
        "# ===============\n",
        "# install java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "# set your spark folder to your system path environment. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After downloading dataset, you should have the files in your Files (click the folder icon in the left sidebar)\n",
        "!wget -O Products_table.csv https://drive.google.com/uc?id=1FG0rGWSPWALcmFo3feHUF5TK5AP7mMwH&export=download #products\n",
        "!wget -O Sales_table.csv https://drive.google.com/uc?id=1l1fr_s67JjGGsXt3fIz_769pKPZg-jhU&export=download #sales\n",
        "!wget -O Sellers_table.csv https://drive.google.com/uc?id=1YTTYU5Cwgvau1Z7b1ShmcIhrO3VN-Zhq&export=download #sellers"
      ],
      "metadata": {
        "id": "2luSAeOXxBiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30a8804-ec81-40b9-fee4-75695a05b472"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-01 07:44:20--  https://drive.google.com/uc?id=1FG0rGWSPWALcmFo3feHUF5TK5AP7mMwH\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.62.102, 172.253.62.101, 172.253.62.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.62.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-a0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ab6p3ngbtar5an2on9cmgujhd9g8fv8s/1680335025000/06948221057362969045/*/1FG0rGWSPWALcmFo3feHUF5TK5AP7mMwH?uuid=f06e982f-d973-436c-9393-57d6a308ac28 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-01 07:44:22--  https://doc-0g-a0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ab6p3ngbtar5an2on9cmgujhd9g8fv8s/1680335025000/06948221057362969045/*/1FG0rGWSPWALcmFo3feHUF5TK5AP7mMwH?uuid=f06e982f-d973-436c-9393-57d6a308ac28\n",
            "Resolving doc-0g-a0-docs.googleusercontent.com (doc-0g-a0-docs.googleusercontent.com)... 142.251.16.132, 2607:f8b0:4004:c17::84\n",
            "Connecting to doc-0g-a0-docs.googleusercontent.com (doc-0g-a0-docs.googleusercontent.com)|142.251.16.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2430503 (2.3M) [text/csv]\n",
            "Saving to: ‘Products_table.csv’\n",
            "\n",
            "Products_table.csv  100%[===================>]   2.32M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-04-01 07:44:22 (172 MB/s) - ‘Products_table.csv’ saved [2430503/2430503]\n",
            "\n",
            "--2023-04-01 07:44:22--  https://drive.google.com/uc?id=1l1fr_s67JjGGsXt3fIz_769pKPZg-jhU\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.62.102, 172.253.62.101, 172.253.62.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.62.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0s-a0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2jkiojsvrjm3hhndv404o40lq13qiu9n/1680335025000/06948221057362969045/*/1l1fr_s67JjGGsXt3fIz_769pKPZg-jhU?uuid=5dcf93bd-7049-4f0c-87a4-9cca0ccc97b8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-01 07:44:23--  https://doc-0s-a0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2jkiojsvrjm3hhndv404o40lq13qiu9n/1680335025000/06948221057362969045/*/1l1fr_s67JjGGsXt3fIz_769pKPZg-jhU?uuid=5dcf93bd-7049-4f0c-87a4-9cca0ccc97b8\n",
            "Resolving doc-0s-a0-docs.googleusercontent.com (doc-0s-a0-docs.googleusercontent.com)... 142.251.16.132, 2607:f8b0:4004:c17::84\n",
            "Connecting to doc-0s-a0-docs.googleusercontent.com (doc-0s-a0-docs.googleusercontent.com)|142.251.16.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6957214 (6.6M) [text/csv]\n",
            "Saving to: ‘Sales_table.csv’\n",
            "\n",
            "Sales_table.csv     100%[===================>]   6.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-04-01 07:44:24 (47.6 MB/s) - ‘Sales_table.csv’ saved [6957214/6957214]\n",
            "\n",
            "--2023-04-01 07:44:24--  https://drive.google.com/uc?id=1YTTYU5Cwgvau1Z7b1ShmcIhrO3VN-Zhq\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.62.102, 172.253.62.101, 172.253.62.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.62.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-a0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/o2lee08rjsa23g6qqfq0h7vir2j7pdp9/1680335025000/06948221057362969045/*/1YTTYU5Cwgvau1Z7b1ShmcIhrO3VN-Zhq?uuid=dd170bd2-f770-4e66-be3e-6594ffa83dfd [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-01 07:44:24--  https://doc-14-a0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/o2lee08rjsa23g6qqfq0h7vir2j7pdp9/1680335025000/06948221057362969045/*/1YTTYU5Cwgvau1Z7b1ShmcIhrO3VN-Zhq?uuid=dd170bd2-f770-4e66-be3e-6594ffa83dfd\n",
            "Resolving doc-14-a0-docs.googleusercontent.com (doc-14-a0-docs.googleusercontent.com)... 142.251.16.132, 2607:f8b0:4004:c17::84\n",
            "Connecting to doc-14-a0-docs.googleusercontent.com (doc-14-a0-docs.googleusercontent.com)|142.251.16.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1077818 (1.0M) [text/csv]\n",
            "Saving to: ‘Sellers_table.csv’\n",
            "\n",
            "Sellers_table.csv   100%[===================>]   1.03M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-01 07:44:24 (57.8 MB/s) - ‘Sellers_table.csv’ saved [1077818/1077818]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv files into dataframes, you can work with the 3 tables after running this code\n",
        "products_table = spark.read.option('header', True).option('inferSchema', True).csv(\"/content/Products_table.csv\").repartition(1).cache()\n",
        "sales_table = spark.read.option('header', True).option('inferSchema', True).csv(\"/content/Sales_table.csv\").repartition(1).cache()\n",
        "sellers_table = spark.read.option('header', True).option('inferSchema', True).csv(\"/content/Sellers_table.csv\").repartition(1).cache()"
      ],
      "metadata": {
        "id": "haSMnjoBxCOs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_table"
      ],
      "metadata": {
        "id": "90QH4t_XNXM0",
        "outputId": "6df55ddf-0770-4faf-ae1b-38525803da43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[product_id: int, product_name: string, price: int]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_table"
      ],
      "metadata": {
        "id": "zV9-Vp5BN73e",
        "outputId": "b7efca13-2931-4f64-8c97-0b85ce133457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[order_id: int, product_id: int, seller_id: int, num_of_items_sold: int]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sellers_table"
      ],
      "metadata": {
        "id": "eieThlgaN8IZ",
        "outputId": "97d632f4-4ae1-4e8e-fee0-1621a9f68f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[seller_id: int, seller_name: string, rating: int]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add all imports\n",
        "from pyspark.sql.functions import sum, asc, desc, col"
      ],
      "metadata": {
        "id": "WQLSDTxaQ6j-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (a) Output the top 3 most popular products sold among all sellers [2m]\n",
        "# Your table should have 1 column(s): [product_name]\n",
        "\n",
        "top_3_products = (\n",
        "    sales_table\n",
        "    .groupBy('product_id')\n",
        "    .sum('num_of_items_sold')\n",
        "    .withColumnRenamed('sum(num_of_items_sold)', 'total_items_sold')\n",
        "    .join(products_table, 'product_id')\n",
        "    .select('product_name')\n",
        "    .orderBy(col('total_items_sold').desc())\n",
        "    .limit(3)\n",
        ")\n",
        "\n",
        "top_3_products.show()"
      ],
      "metadata": {
        "id": "vccDBf_CxC0a",
        "outputId": "4e028445-7369-426b-8c8e-dc13a785aef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "| product_name|\n",
            "+-------------+\n",
            "|product_51270|\n",
            "|product_18759|\n",
            "|product_59652|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (b) Find out the total sales of the products sold by sellers 1 to 10 and output the top most sold product [2m]\n",
        "# Your table should have 1 column(s): [product_name]\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# filter the sellers for seller 1 to 10\n",
        "filtered_sellers = sales_table.filter(col('seller_id').between(1, 10))\n",
        "\n",
        "top_product_for_seller_1_to_10 = (\n",
        "    filtered_sellers\n",
        "    .groupBy('product_id')\n",
        "    .agg(sum('num_of_items_sold').alias('total_items_sold'))\n",
        "    .join(products_table, 'product_id')\n",
        "    .select('product_name')\n",
        "    .orderBy(desc('total_items_sold'))\n",
        "    .limit(1)\n",
        ")\n",
        "\n",
        "top_product_for_seller_1_to_10.show()"
      ],
      "metadata": {
        "id": "Ljmb_1OaxC8Q",
        "outputId": "92f27d96-e776-4c23-b413-b7cf56bf5d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "| product_name|\n",
            "+-------------+\n",
            "|product_36658|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (c) Compute the combined revenue earned from sellers where seller_id ranges from 1 to 500 inclusive. [3m]\n",
        "# Your table should have 1 column(s): [total_revenue]\n",
        "\n",
        "revenue = (\n",
        "    sales_table\n",
        "    .filter(col('seller_id').between(1, 500))\n",
        "    .join(products_table, 'product_id')\n",
        "    .withColumn('revenue', col('num_of_items_sold') * col('price'))\n",
        "    .agg(sum('revenue').alias('total_revenue'))\n",
        ")\n",
        "\n",
        "revenue.show()"
      ],
      "metadata": {
        "id": "QtinRRycxDBS",
        "outputId": "75d25a3d-ea65-47bc-a2fe-48f62d23b228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|total_revenue|\n",
            "+-------------+\n",
            "|    160916699|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (d) Among sellers with rating >= 4 who have achieved a combined number of products sold >= 3000, find out the top 10 most expensive product sold by any of the sellers. (If there are multiple products at the same price, please sort them in ascending order of product_id) [8m]\n",
        "# Your table should have 1 column(s): [product_name]\n",
        "# To get the full mark, your query should not run for more than 1 min\n",
        "\n",
        "high_rating_sellers = sellers_table.filter(col('rating') >= 4)\n",
        "\n",
        "# sellers with rating >= 4 who have achieved a combined number of products sold >= 3000\n",
        "sales_high_rating_sellers = (\n",
        "    sales_table\n",
        "    .join(high_rating_sellers, 'seller_id')\n",
        "    .groupBy('seller_id')\n",
        "    .agg(sum('num_of_items_sold').alias('total_items_sold'))\n",
        "    .filter(col('total_items_sold') >= 3000)\n",
        ")\n",
        "\n",
        "# For video illustration\n",
        "sales_high_rating_sellers.show(10)\n",
        "\n",
        "# sellers and their product that they sold\n",
        "seller_with_product_sold = (\n",
        "    sales_high_rating_sellers\n",
        "    .join(sales_table, 'seller_id')\n",
        ")\n",
        "\n",
        "# For video illustration\n",
        "seller_with_product_sold.show(10)\n",
        "\n",
        "# top 10 most expensive product sold by any of the sellers.\n",
        "# If there are multiple products at the same price, please sort them in ascending order of product_id)\n",
        "top_expensive_products = (\n",
        "    seller_with_product_sold\n",
        "    .join(products_table, 'product_id')\n",
        "    .select('product_name')\n",
        "    .orderBy(desc('price'), asc('product_id'))\n",
        "    .limit(10)\n",
        ")\n",
        "\n",
        "# Final Result\n",
        "top_expensive_products.show(10)\n"
      ],
      "metadata": {
        "id": "S-iyIoUKxada",
        "outputId": "6bbe70e1-f1c9-4083-a533-cd6a1470515d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------+\n",
            "|seller_id|total_items_sold|\n",
            "+---------+----------------+\n",
            "|    23608|            6285|\n",
            "|    34610|            4441|\n",
            "|     1543|            4147|\n",
            "|    10269|            3071|\n",
            "|    38703|            3897|\n",
            "|    35872|            4955|\n",
            "|    39620|            5147|\n",
            "|    31478|            3384|\n",
            "|    16139|            3577|\n",
            "|    13309|            4448|\n",
            "+---------+----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+---------+----------------+--------+----------+-----------------+\n",
            "|seller_id|total_items_sold|order_id|product_id|num_of_items_sold|\n",
            "+---------+----------------+--------+----------+-----------------+\n",
            "|    23608|            6285|  293756|     95179|              673|\n",
            "|    23608|            6285|  175321|     51037|              531|\n",
            "|    23608|            6285|  149971|     49213|              840|\n",
            "|    23608|            6285|  147765|     16749|              898|\n",
            "|    23608|            6285|  128426|     51717|               39|\n",
            "|    23608|            6285|   65018|     40479|              415|\n",
            "|    23608|            6285|   49187|     66413|              365|\n",
            "|    23608|            6285|   46291|     96847|              740|\n",
            "|    23608|            6285|   22816|     95632|              934|\n",
            "|    23608|            6285|       3|     76927|              850|\n",
            "+---------+----------------+--------+----------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+------------+\n",
            "|product_name|\n",
            "+------------+\n",
            "| product_106|\n",
            "| product_117|\n",
            "| product_363|\n",
            "| product_712|\n",
            "| product_712|\n",
            "| product_843|\n",
            "| product_897|\n",
            "| product_897|\n",
            "| product_923|\n",
            "|product_1466|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Spark ML (10m)"
      ],
      "metadata": {
        "id": "f_mZhcusW0-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Spark\n",
        "# ===============\n",
        "# Installing Spark needs to be done once each time you re-open this notebook. It should take around 10-30 seconds.\n",
        "# ===============\n",
        "# install java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "# set your spark folder to your system path environment. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "HxxRailSWpb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After downloading dataset, you should have the files in your Files (click the folder icon in the left sidebar)\n",
        "!wget -O bank_train.csv https://drive.google.com/uc?id=1kEP94BfULB3gUMl_IQCg9wuX4IJRajMC&export=download #products\n",
        "!wget -O bank_test.csv https://drive.google.com/uc?id=1EqX4liL5iWbwqyJ_lFaYvYZvgBFwpwSJ&export=download #bank_test"
      ],
      "metadata": {
        "id": "qCqPHSerW_al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e47bc1e-dcef-4a0e-a212-fa2cb40fd3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-05 13:59:46--  https://drive.google.com/uc?id=1kEP94BfULB3gUMl_IQCg9wuX4IJRajMC\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.8.102, 142.251.8.113, 142.251.8.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.8.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/6a3e19tqodgib3pccobtlthqmdiclhtv/1678024725000/08487103376102314083/*/1kEP94BfULB3gUMl_IQCg9wuX4IJRajMC?uuid=d11faedd-8c48-4734-aa0b-18efe2a56d2e [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-05 13:59:47--  https://doc-0c-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/6a3e19tqodgib3pccobtlthqmdiclhtv/1678024725000/08487103376102314083/*/1kEP94BfULB3gUMl_IQCg9wuX4IJRajMC?uuid=d11faedd-8c48-4734-aa0b-18efe2a56d2e\n",
            "Resolving doc-0c-a8-docs.googleusercontent.com (doc-0c-a8-docs.googleusercontent.com)... 142.250.157.132, 2404:6800:4008:c13::84\n",
            "Connecting to doc-0c-a8-docs.googleusercontent.com (doc-0c-a8-docs.googleusercontent.com)|142.250.157.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 730948 (714K) [text/csv]\n",
            "Saving to: ‘bank_train.csv’\n",
            "\n",
            "bank_train.csv      100%[===================>] 713.82K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-03-05 13:59:47 (125 MB/s) - ‘bank_train.csv’ saved [730948/730948]\n",
            "\n",
            "--2023-03-05 13:59:47--  https://drive.google.com/uc?id=1EqX4liL5iWbwqyJ_lFaYvYZvgBFwpwSJ\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.8.102, 142.251.8.113, 142.251.8.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.8.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rkbtpgg27v2cn72q9ctopd4jq0s78b5a/1678024725000/08487103376102314083/*/1EqX4liL5iWbwqyJ_lFaYvYZvgBFwpwSJ?uuid=a43cbd1e-1501-4e67-bb91-6bcc3290a4f6 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-05 13:59:48--  https://doc-08-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rkbtpgg27v2cn72q9ctopd4jq0s78b5a/1678024725000/08487103376102314083/*/1EqX4liL5iWbwqyJ_lFaYvYZvgBFwpwSJ?uuid=a43cbd1e-1501-4e67-bb91-6bcc3290a4f6\n",
            "Resolving doc-08-a8-docs.googleusercontent.com (doc-08-a8-docs.googleusercontent.com)... 142.250.157.132, 2404:6800:4008:c13::84\n",
            "Connecting to doc-08-a8-docs.googleusercontent.com (doc-08-a8-docs.googleusercontent.com)|142.250.157.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182844 (179K) [text/csv]\n",
            "Saving to: ‘bank_test.csv’\n",
            "\n",
            "bank_test.csv       100%[===================>] 178.56K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-03-05 13:59:49 (101 MB/s) - ‘bank_test.csv’ saved [182844/182844]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bank_train_location = \"/content/bank_train.csv\"\n",
        "bank_test_location = \"/content/bank_test.csv\"\n",
        "file_type = \"csv\"\n",
        "\n",
        "# CSV options\n",
        "infer_schema = \"true\"\n",
        "first_row_is_header = \"true\"\n",
        "delimiter = \",\"\n",
        "\n",
        "# The applied options are for CSV files. For other file types, these will be ignored.\n",
        "bank_train = spark.read.format(file_type) \\\n",
        "  .option(\"inferSchema\", infer_schema) \\\n",
        "  .option(\"header\", first_row_is_header) \\\n",
        "  .option(\"sep\", delimiter) \\\n",
        "  .load(bank_train_location)\n",
        "\n",
        "bank_test = spark.read.format(file_type) \\\n",
        "  .option(\"inferSchema\", infer_schema) \\\n",
        "  .option(\"header\", first_row_is_header) \\\n",
        "  .option(\"sep\", delimiter) \\\n",
        "  .load(bank_test_location)"
      ],
      "metadata": {
        "id": "VV27jT7wWoHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build ML model to predict whether the customer will subscribe bank deposit service or not. Train the model using training set and evaluate the model performance (e.g. accuracy) using testing set.\n",
        "\n",
        "\n",
        "*   You can explore different methods to pre-process the data and select proper features\n",
        "*   You can explore different methods to pre-process the data and select proper features\n",
        "*   Present the final testing accuracy."
      ],
      "metadata": {
        "id": "fIoXrjaq5OG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation (4m)\n"
      ],
      "metadata": {
        "id": "tMW6Ltcr5J06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model building (4m)"
      ],
      "metadata": {
        "id": "PaULiAZv5Npd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation (2m)"
      ],
      "metadata": {
        "id": "ZYTCRALv5iyF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}